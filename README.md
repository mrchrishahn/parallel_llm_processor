# Parallel LLM Processor

A CLI tool for processing multiple LLM prompts in parallel using OpenRouter API with Bun runtime. OpenRouter provides access to 400+ AI models through a single API, including GPT, Claude, Gemini, Llama, and many more.

## Features

- üöÄ **Parallel Processing**: Run multiple prompts simultaneously with configurable concurrency
- üîÑ **Dynamic Model Discovery**: Automatically fetch and select from 300+ available models
- üéØ **Smart Model Selection**: Popular models highlighted, with real-time pricing and context info
- ‚öôÔ∏è **Configurable Settings**: Adjust temperature, max tokens, thinking mode, and other parameters
- üìÅ **Flexible Input**: Process `.txt`, `.md`, or extensionless files as prompts
- üìä **Detailed Results**: Get comprehensive processing statistics and error reporting
- üé® **Beautiful CLI**: Interactive prompts with colorful output and progress indicators
- üîë **API Key Validation**: Test API keys before processing begins

## Installation

Make sure you have [Bun](https://bun.sh) installed, then:

```bash
bun install
```

## Quick Start

1. **Get an OpenRouter API key**: Sign up at [OpenRouter](https://openrouter.ai) and get your API key

2. **Set your API key** (optional):
   ```bash
   export OPENROUTER_API_KEY=your-api-key-here
   ```

3. **Create example prompts**:
   ```bash
   bun prompt init
   ```

4. **Process the prompts**:
   ```bash
   bun prompt run
   ```

## Usage

### Initialize Example Prompts

Create a directory with example prompt files:

```bash
bun prompt init -d ./my-prompts
```

### Process Prompts

Run the interactive CLI to process prompts:

```bash
bun prompt run
```

The CLI will:
1. Test your API key
2. Fetch all available models from OpenRouter (300+)
3. Show popular models first for easy selection
4. Configure model parameters interactively
5. Process all prompts in parallel

Or use command line options:

```bash
bun prompt run \
  --directory ./prompts \
  --api-key your-api-key \
  --model anthropic/claude-3.5-sonnet \
  --concurrent 5
```

### Command Line Options

- `-d, --directory <path>`: Directory containing prompt files
- `-k, --api-key <key>`: OpenRouter API key
- `-m, --model <model>`: Model to use (must be available on OpenRouter)
- `-c, --concurrent <number>`: Number of concurrent requests (default: 3)

## Available Models

The tool automatically fetches all available models from OpenRouter, including:

### üî• Popular Models
- **Claude 3.5 Sonnet** - Anthropic's most capable model
- **GPT-4o** - OpenAI's flagship multimodal model
- **GPT-4o Mini** - Fast and cost-effective
- **o1-preview** - OpenAI's reasoning model
- **Gemini Pro 1.5** - Google's advanced model
- **Llama 3.2 90B** - Meta's open-source model
- **Qwen 2.5 72B** - Alibaba's multilingual model
- **And many more...**

### Dynamic Features
- **Real-time Pricing**: See cost per token for each model
- **Context Length**: View maximum context window size
- **Model Validation**: Automatically verify model availability
- **Smart Filtering**: Popular models highlighted for easy selection

## File Structure

The tool processes files in the specified directory:

```
prompts/
‚îú‚îÄ‚îÄ prompt1.txt          # Input prompt
‚îú‚îÄ‚îÄ prompt1_result.txt   # Generated result
‚îú‚îÄ‚îÄ prompt2.md           # Markdown prompt
‚îú‚îÄ‚îÄ prompt2_result.txt   # Generated result
‚îî‚îÄ‚îÄ analysis             # Extensionless file
‚îî‚îÄ‚îÄ analysis_result.txt
```

## Configuration

The CLI will interactively ask for:

1. **Directory**: Path to folder containing prompt files
2. **API Key**: OpenRouter API key (or use environment variable)
3. **Model**: Choose from 300+ available models with live pricing
4. **Model Settings**:
   - Temperature (0.0-2.0)
   - Max tokens
   - Top P (0.0-1.0)
   - Thinking/reasoning mode (for supported models)

## Examples

### Example Prompt Files

**creative_story.txt**:
```
Write a short creative story about a robot who discovers they can dream. The story should be engaging and thought-provoking, exploring themes of consciousness and identity.
```

**code_review.txt**:
```
Review the following Python code and suggest improvements:

def calculate_average(numbers):
    total = 0
    for i in range(len(numbers)):
        total = total + numbers[i]
    avg = total / len(numbers)
    return avg
```

### Expected Output

```
‚úÖ Using OpenRouter API key from environment
‚úÖ Fetched 347 available models

üî• Popular Models
‚ùØ anthropic/claude-3.5-sonnet (200k ctx) - $0.000003/$0.000015
  openai/gpt-4o (128k ctx) - $0.000005/$0.000015
  openai/gpt-4o-mini (128k ctx) - $0.000000/$0.000001
  openai/o1-preview (128k ctx) - $0.000015/$0.000060

üìä Results Summary:
  Total files: 4
  Successful: 4
  Failed: 0
  Total time: 8234ms
  Average time per request: 2058ms
  Provider: OpenRouter
```

## Environment Variables

Set your OpenRouter API key:

```bash
export OPENROUTER_API_KEY=your-openrouter-key
```

You can also copy `env.example` to `.env` and set your keys there.

## Error Handling

The tool handles various error scenarios:
- Invalid API keys (tested before processing)
- Network timeouts
- Rate limiting
- Model unavailability
- Malformed prompt files
- Directory access issues

All errors are reported with detailed messages and timing information.

## Why OpenRouter?

- **300+ Models**: Access to the largest collection of AI models
- **Single API**: One key for GPT, Claude, Gemini, Llama, and more
- **Competitive Pricing**: Often better rates than direct provider APIs
- **Model Routing**: Automatic fallbacks and load balancing
- **Real-time Availability**: Always up-to-date model listings

## Development

```bash
# Run in development mode
bun run dev

# Build for production
bun run build

# Run built version
bun run start
```

## Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Test thoroughly
5. Submit a pull request

## License

MIT License - see LICENSE file for details. 